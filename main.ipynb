{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc655fb4",
   "metadata": {},
   "source": [
    "# BangleBeat\n",
    "\n",
    "The following notebook walks through the process of making a machine learning model to improve BangleJS2 heart rate accuracy based on prior data. The ML model runs directly on the BangleJS2 watch and should serve as an easy to use pipeline for folks to make thier own Bangle more accurate for them. Further work may attempt to generalize this approach to yield an open source watch which actively learns how to improve its own heart rate measurements. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a7b642",
   "metadata": {},
   "source": [
    "\n",
    "## Data Capture\n",
    "\n",
    "First, we should assess how good or bad the BangleJS2 performs when compared to other wearable devices. This includes the following devices:\n",
    "\n",
    "- BangleJS2 Smart Watch\n",
    "- Garmin Instinct 2X Smart Watch\n",
    "- Polar H10 ECG Chest Strap\n",
    "\n",
    "These are all supported to a sufficient degree by [Gadgetbridge](https://gadgetbridge.org/). However, in the initial phases of this project I found that the BangleJS2 does not sample heart rate data nearly as fast as the Garmin does. To give this model a fighting chance I wrote [loglog](https://github.com/lucspec/BangleApps/tree/master/apps/loglog) -- a BangleJS2 app to prioritize data collection over battery life. Initial testing yields a high enough data density to be more comprable with the other two sensors in this work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e9005b",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "With our sensors and collection mechanisms in place, we can start looking at some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5973b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from typing import Optional, List\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from scipy import stats\n",
    "    import seaborn as sns\n",
    "except ImportError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Run: poetry install --with analysis\")\n",
    "    sys.exit(1)\n",
    "\n",
    "from lib.hrDataLoaders import getGadgetbridgeData, getLoglogCsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdeb810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineHrData(*dataframes: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Combine multiple heart rate dataframes\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    *dataframes : pd.DataFrame\n",
    "        Variable number of dataframes to combine\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Combined dataframe with standard columns\n",
    "    \"\"\"\n",
    "    # Filter out empty dataframes\n",
    "    valid_dfs = [df for df in dataframes if not df.empty]\n",
    "    \n",
    "    if not valid_dfs:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Ensure all dataframes have the required columns\n",
    "    required_cols = ['device_name', 'TIMESTAMP', 'HEART_RATE', 'datetime']\n",
    "    \n",
    "    standardized_dfs = []\n",
    "    for df in valid_dfs:\n",
    "        if all(col in df.columns for col in required_cols):\n",
    "            # Keep only required columns plus any extras\n",
    "            standardized_dfs.append(df)\n",
    "        else:\n",
    "            print(f\"Warning: Dataframe missing required columns, skipping\")\n",
    "    \n",
    "    if standardized_dfs:\n",
    "        return pd.concat(standardized_dfs, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c050395",
   "metadata": {},
   "source": [
    "With some boilerplate out of the way, let's load up our data and see what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527c4549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DB_PATH = \"./data/Gadgetbridge.db\"\n",
    "LOGLOG_CSV = \"./data/Gadgetbridge.db\"\n",
    "\n",
    "# Load Gadgetbridge data\n",
    "gb_data = getGadgetbridgeData(DB_PATH)\n",
    "print(f\"Loaded {len(gb_data)} Gadgetbridge measurements\")\n",
    "\n",
    "# Load custom app data if path provided\n",
    "if LOGLOG_CSV:\n",
    "    #loglog_data = getLoglogCsv(LOGLOG_CSV, device_name='loglog')\n",
    "    loglog_data = getLoglogData(LOGLOG_CSV, device_name='loglog')\n",
    "    print(f\"Loaded {len(loglog_data)} custom app measurements\")\n",
    "else:\n",
    "    print(\"\\nNo loglog CSV provided\")\n",
    "    loglog_data = pd.DataFrame()\n",
    "\n",
    "# Combine all data\n",
    "print(\"\\nCombining all data sources...\")\n",
    "hr_data = combineHrData(gb_data, loglog_data)\n",
    "\n",
    "if hr_data.empty:\n",
    "    print(\"No heart rate data found!\")\n",
    "\n",
    "print(f\"\\nTotal HR measurements: {len(hr_data)}\")\n",
    "print(f\"Date range: {hr_data['datetime'].min()} to {hr_data['datetime'].max()}\")\n",
    "print(f\"\\nDevices found:\")\n",
    "for device in sorted(hr_data['device_name'].unique()):\n",
    "    count = len(hr_data[hr_data['device_name'] == device])\n",
    "    date_range = hr_data[hr_data['device_name'] == device]['datetime']\n",
    "    print(f\"  - {device}: {count:,} measurements ({date_range.min()} to {date_range.max()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11efce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DEVICE STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "stats_df = calculate_device_statistics(hr_data)\n",
    "print(stats_df.to_string(index=False, float_format=lambda x: f'{x:.2f}'))\n",
    "\n",
    "# Compare with Polar H10\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ACCURACY COMPARISON (vs Polar H10 Chest Strap)\")\n",
    "print(\"=\"*80)\n",
    "polar_comparison = compare_with_polar(hr_data, tolerance_seconds=60)\n",
    "if polar_comparison is not None and not polar_comparison.empty:\n",
    "    print(polar_comparison.to_string(index=False, float_format=lambda x: f'{x:.2f}'))\n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"  - MAE/RMSE: Lower is better (how many bpm off on average)\")\n",
    "    print(\"  - Correlation: Closer to 1.0 is better (how well it tracks changes)\")\n",
    "    print(\"  - Mean Diff: Positive = reads higher than Polar, Negative = reads lower\")\n",
    "else:\n",
    "    print(\"Not enough simultaneous measurements to compare devices\")\n",
    "    print(\"(Devices need to be worn at the same time within 60 seconds)\")\n",
    "\n",
    "# Generate visualizations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. Heart rate distributions (raw BPM)...\")\n",
    "plot_hr_distributions(hr_data, normalized=False)\n",
    "\n",
    "print(\"2. Heart rate distributions (normalized 0-1)...\")\n",
    "plot_hr_distributions(hr_data, normalized=True)\n",
    "\n",
    "print(\"3. Heart rate timeline (raw BPM)...\")\n",
    "plot_hr_timeline(hr_data, max_hours=48, normalized=False)\n",
    "\n",
    "print(\"4. Heart rate timeline (normalized 0-1)...\")\n",
    "plot_hr_timeline(hr_data, max_hours=48, normalized=True)\n",
    "\n",
    "if 'Polar H10' in hr_data['device_name'].values:\n",
    "    print(\"5. Bland-Altman comparison (medical-grade accuracy plot)...\")\n",
    "    plot_bland_altman(hr_data, tolerance_seconds=60)\n",
    "\n",
    "    print(\"6. Scatter plot comparison...\")\n",
    "    plot_scatter_comparison(hr_data, tolerance_seconds=60)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Analysis complete!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
